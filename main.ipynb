{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f8TImfXqOOom"
   },
   "source": [
    "# Training and saving a model. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 556
    },
    "executionInfo": {
     "elapsed": 782,
     "status": "error",
     "timestamp": 1684781538049,
     "user": {
      "displayName": "Adnan Harun DOĞAN",
      "userId": "10197058931241530903"
     },
     "user_tz": -180
    },
    "id": "tcmbuzZiiP5c",
    "outputId": "1ab61918-a287-4484-deb4-de2e2988f3d9",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ceng796/miniconda3/envs/796/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from model import Generator, Discriminator\n",
    "from latent_learner import LatentLearner\n",
    "from dataset import Dataset\n",
    "from tqdm import tqdm\n",
    "import loss\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import gc\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def save_samples(x_1, x_2, generator, latent_learner, iter_):\n",
    "    os.makedirs(\"samples\", exist_ok=True)\n",
    "\n",
    "    generator.eval()\n",
    "    latent_learner.eval()\n",
    "\n",
    "    for i in range(len(x_1)):\n",
    "        noise_1 = torch.unsqueeze(x_1[i], 0)\n",
    "        noise_2 = torch.unsqueeze(x_2[i], 0)\n",
    "\n",
    "        noise = torch.cat([noise_1, noise_2], axis=-1)\n",
    "        # Map to latent\n",
    "        w = latent_learner(noise)\n",
    "\n",
    "        # Pass through Generator\n",
    "        samples, _ = generator([w], input_is_latent=True)\n",
    "\n",
    "        # Save for later examination\n",
    "        torchvision.utils.save_image(\n",
    "            samples.detach().clamp_(min=-1, max=1),\n",
    "            f\"samples/samples_{iter_}_{i}.png\",\n",
    "            nrow=1,\n",
    "            normalize=True,\n",
    "            range=(-1, 1),\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 556
    },
    "executionInfo": {
     "elapsed": 782,
     "status": "error",
     "timestamp": 1684781538049,
     "user": {
      "displayName": "Adnan Harun DOĞAN",
      "userId": "10197058931241530903"
     },
     "user_tz": -180
    },
    "id": "tcmbuzZiiP5c",
    "outputId": "1ab61918-a287-4484-deb4-de2e2988f3d9"
   },
   "outputs": [],
   "source": [
    "def disable_grad(model):\n",
    "    for _, param in model.named_parameters():\n",
    "        param.requires_grad = False\n",
    "\n",
    "def train(device, max_iters=150):\n",
    "    torch.manual_seed(1)\n",
    "    np.random.seed(1)\n",
    "    random.seed(1)\n",
    "\n",
    "    cnn_normalization_mean = torch.tensor([0.485, 0.456, 0.406]).to(device)\n",
    "    cnn_normalization_std = torch.tensor([0.229, 0.224, 0.225]).to(device)\n",
    "    style_layers_default = ['conv_1', 'conv_2', 'conv_3', 'conv_4', 'conv_5']\n",
    "\n",
    "    generator = Generator(size=256, style_dim=512, n_mlp=8).to(device)\n",
    "    discriminator = Discriminator(size=256).to(device)\n",
    "    latent_learner = LatentLearner().to(device)\n",
    "\n",
    "    vgg = torchvision.models.vgg19(weights='IMAGENET1K_V1').features.to(device).eval()\n",
    "\n",
    "    # No need for gradients on the parameters of these\n",
    "    disable_grad(generator)\n",
    "    disable_grad(vgg)\n",
    "\n",
    "    # Take sub-networks from the vgg, later used to compute style loss\n",
    "    subnetworks = loss.subnetworks(vgg, max_layers=5)\n",
    "\n",
    "    # Garbage collection\n",
    "#    del vgg\n",
    "#    gc.collect()\n",
    "#    torch.cuda.empty_cache()\n",
    "\n",
    "    # Load checkpoint and weights\n",
    "    ckpt = torch.load(\"550000.pt\")\n",
    "\n",
    "    generator.load_state_dict(ckpt[\"g_ema\"], strict=False)\n",
    "    generator.eval()\n",
    "\n",
    "    discriminator.load_state_dict(ckpt[\"d\"])\n",
    "\n",
    "    # Initialize optimizers (no optimizer for generator :)\n",
    "    disc_opt = torch.optim.Adam(\n",
    "        discriminator.parameters(),\n",
    "        lr = 5e-4,\n",
    "        betas = (0.0, 0.99)\n",
    "    )\n",
    "    latent_learner_opt = torch.optim.Adam(\n",
    "        latent_learner.parameters(),\n",
    "        lr = 5e-4,\n",
    "        betas = (0.0, 0.99)\n",
    "    )\n",
    "\n",
    "    # Simple transformation pipeline\n",
    "    transforms = torchvision.transforms.Compose([\n",
    "        torchvision.transforms.Resize((256, 256)),\n",
    "        torchvision.transforms.ToTensor(),\n",
    "        torchvision.transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])\n",
    "    ])\n",
    "\n",
    "    # style loss normalization\n",
    "    style_norm = torchvision.transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "\n",
    "    # Create simple dataset & loader\n",
    "    x_1 = torch.randn(10, 14, 512, device=device)\n",
    "    x_2 = torch.randn(10, 14, 512, device=device)\n",
    "\n",
    "    dataset = Dataset(path=\"./babies\", device=device, transforms=transforms)\n",
    "\n",
    "    bar = tqdm(range(max_iters), dynamic_ncols=True)\n",
    "\n",
    "    # 150 iterations\n",
    "    for idx in bar:\n",
    "        i = np.random.choice(10, size=4, replace=False)\n",
    "        imgs = dataset[i]\n",
    "\n",
    "#        noise = x[i]\n",
    "\n",
    "        idx_1 = np.random.choice(10, size=imgs.shape[0], replace=False)\n",
    "        idx_2 = np.random.choice(10, size=imgs.shape[0], replace=False)\n",
    "\n",
    "        x = torch.cat([x_1[idx_1], x_2[idx_2]], axis=-1)\n",
    "\n",
    "        ##### Adversarial Loss ##### \n",
    "        # first forward pass\n",
    "        w = latent_learner(x)\n",
    "        samples, _ = generator([w], input_is_latent=True)\n",
    "\n",
    "        real_scores = discriminator(imgs)\n",
    "        fake_scores = discriminator(samples)\n",
    "\n",
    "        d_loss = loss.d_logistic_loss(real_scores, fake_scores)\n",
    "\n",
    "        # optimization step on discriminator\n",
    "        disc_opt.zero_grad()\n",
    "        d_loss.backward()\n",
    "        disc_opt.step()\n",
    "\n",
    "        # second forward pass (needed)\n",
    "        w = latent_learner(x)\n",
    "        samples, _ = generator([w], input_is_latent=True)\n",
    "\n",
    "        fake_scores = discriminator(samples)\n",
    "\n",
    "        g_loss = 5 * (1 - idx/max_iters) * loss.g_nonsaturating_loss(fake_scores)\n",
    "\n",
    "        # optimization step on latent learner\n",
    "        latent_learner_opt.zero_grad()\n",
    "        g_loss.backward()\n",
    "        latent_learner_opt.step()\n",
    "\n",
    "        ##### Style Loss #####\n",
    "        idx_1 = np.random.choice(10, size=5, replace=False)\n",
    "\n",
    "        for i in idx_1:\n",
    "            img_idx = np.random.randint(0, 10)\n",
    "            img = torch.unsqueeze(dataset[img_idx], 0)\n",
    "\n",
    "            noise_1 = torch.unsqueeze(x_1[i], 0)\n",
    "            noise_2 = torch.unsqueeze(x_2[img_idx], 0)\n",
    "\n",
    "            x = torch.cat([noise_1, noise_2], axis=-1)\n",
    "\n",
    "            w = latent_learner(x)\n",
    "            sample, _ = generator([w], input_is_latent=True)\n",
    "\n",
    "            # normalize img and sample\n",
    "            style_loss = 50 * loss.style_loss(subnetworks, style_norm(img), style_norm(sample))\n",
    "\n",
    "            # optimization step on latent learner\n",
    "            latent_learner_opt.zero_grad()\n",
    "            style_loss.backward()\n",
    "            latent_learner_opt.step()\n",
    "\n",
    "        bar.set_description(f\"d_loss: {d_loss.cpu():.2f}, g_loss: {g_loss.cpu():.2f}, style_loss: {style_loss:.2f}\")\n",
    "\n",
    "        if (idx+1) % 50 == 0:\n",
    "            save_samples(x_1, x_2, generator, latent_learner, idx+1)\n",
    "\n",
    "    return torch.cat([x_1, x_2], axis=-1), latent_learner, generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d_loss: 0.60, g_loss: 12.29, style_loss: 4.06:   2%|▋                                    | 1/50 [00:02<01:42,  2.09s/it]"
     ]
    }
   ],
   "source": [
    "noise, latent_learner, generator = train(device, max_iters=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(\"ckpts\", exist_ok=True)\n",
    "\n",
    "torch.save(noise, \"ckpts/noise.pt\")\n",
    "torch.save(latent_learner.state_dict(), \"ckpts/latent_learner.pt\")\n",
    "torch.save(generator.state_dict(), \"ckpts/generator.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "orRKWKuIOOrG"
   },
   "source": [
    "# Loading a pre-trained model and computing qualitative samples/outputs from that model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = Generator(size=256, style_dim=512, n_mlp=8).to(device)\n",
    "generator.load_state_dict(torch.load(\"ckpts/generator.pt\"))\n",
    "generator.eval()\n",
    "\n",
    "latent_learner = LatentLearner().to(device)\n",
    "latent_learner.load_state_dict(torch.load(\"ckpts/latent_learner.pt\"))\n",
    "\n",
    "noise = torch.load(\"ckpts/noise.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    # Map to latent\n",
    "    w = latent_learner(noise)\n",
    "\n",
    "    # Pass through Generator\n",
    "    samples, _ = generator([w], input_is_latent=True)\n",
    "\n",
    "    # Save for later examination\n",
    "    torchvision.utils.save_image(\n",
    "        samples.detach(),\n",
    "        \"samples.png\",\n",
    "        nrow=1,\n",
    "        normalize=True,\n",
    "        range=(-1, 1),\n",
    "    )\n",
    "\n",
    "    from PIL import Image\n",
    "\n",
    "    display(Image.open(\"samples.png\"))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyMtFS0H4B8FkdU6YVuYeyRi",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
